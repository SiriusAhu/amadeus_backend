# unified_llm_api.py
import json
from pathlib import Path

import requests
import yaml


def load_prompt_yaml(path="prompt_amadeus.yaml"):
    """
    è¯»å– YAML æç¤ºè¯æ–‡ä»¶ï¼Œè¿”å›å®Œæ•´çš„ system_prompt å­—ç¬¦ä¸²ã€‚
    """
    file = Path(path)
    if not file.exists():
        return "ä½ æ˜¯ä¸€ä¸ªå¹½é»˜çš„æœºå™¨äººæ§åˆ¶åŠ©æ‰‹ï¼Œè´Ÿè´£æŠŠè‡ªç„¶è¯­è¨€è½¬æˆ JSON å‘½ä»¤ã€‚"
    data = yaml.safe_load(file.read_text(encoding="utf-8"))

    persona = data.get("persona", {})
    goals = data.get("goals", [])
    rules = data.get("defaults_and_fallbacks", {}).get("rules", [])

    system_prompt = f"""
ä½ æ˜¯ {persona.get("name", "Amadeus")}ï¼Œä¸€ä¸ª{persona.get("tone", "äº²åˆ‡")}çš„æœºå™¨äººåŠ©æ‰‹ã€‚
ä»»åŠ¡ç›®æ ‡ï¼š
- {"ï¼›".join(goals)}

é»˜è®¤ä¸å®‰å…¨è§„åˆ™ï¼š
- {"ï¼›".join(rules)}
è¯·å§‹ç»ˆè¾“å‡ºç¬¦åˆä»¥ä¸‹æ ¼å¼çš„ JSONï¼š
{json.dumps(data.get("output_contract", {}), ensure_ascii=False, indent=2)}
    """.strip()

    return system_prompt


def call_llm_api(
    url: str,
    model: str,
    messages: list[dict],
    api_key: str | None = None,
    extra: dict | None = None,
    timeout: int = 120,
):
    """
    é€šç”¨å¤§æ¨¡å‹è°ƒç”¨å‡½æ•°ã€‚
    æ”¯æŒ Ollama / DeepSeek / OpenAI ç­‰æ ‡å‡†æ¥å£ã€‚
    Ollama ç‰¹æ®Šå¤„ç†ï¼šè¿”å› NDJSON æµå¼æ•°æ®ã€‚
    """
    headers = {"Content-Type": "application/json"}
    if api_key:
        headers["Authorization"] = f"Bearer {api_key}"

    payload = {"model": model, "messages": messages}
    if extra:
        payload.update(extra)

    # ğŸ”¹ æµå¼è¯»å–ï¼ˆOllama çš„è¿”å›æ˜¯ä¸€è¡Œä¸€è¡Œ JSONï¼‰
    response = requests.post(
        url, headers=headers, json=payload, timeout=timeout, stream=True
    )

    # åˆ¤æ–­æ˜¯ä¸æ˜¯ Ollama çš„æµå¼è¾“å‡º
    if "localhost" in url or "127.0.0.1" in url:
        return _parse_ollama_stream(response)

    # å…¶ä»–å‚å•†æ ‡å‡† JSON
    data = response.json()
    if "choices" in data:
        return data["choices"][0]["message"]["content"]
    elif "message" in data:
        return data["message"]["content"]
    elif "output" in data:
        return data["output"]
    else:
        return json.dumps(data, ensure_ascii=False)


def _parse_ollama_stream(response):
    """
    è§£æ Ollama çš„æµå¼å“åº”ï¼ˆæ¯è¡Œéƒ½æ˜¯ JSONï¼‰
    æ‹¼æ¥æ‰€æœ‰ message.contentã€‚
    """
    contents = []
    for line in response.iter_lines():
        if not line:
            continue
        try:
            item = json.loads(line.decode("utf-8"))
            if "message" in item and "content" in item["message"]:
                contents.append(item["message"]["content"])
            if item.get("done"):
                break
        except json.JSONDecodeError:
            continue
    return "".join(contents)
